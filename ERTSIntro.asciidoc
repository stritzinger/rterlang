= In-Depth Introduction to ERTS =

== Evaluation of current situation: Use-cases of Erlang ==

* What is hard RT: Never miss a deadline: "controls an environment by receiving data,
processing them, and returning the results
sufficiently quickly to affect the environment at that
time." _Martin, James (1965)_. Programming Real-time Computer Systems
* No deadline guarantees

=== Garbage Collection ===

Source https://www.erlang-solutions.com/yxblog/erlang-19-0-garbage-collector.html[Erlang Solutions Blog: Erlang 19.0 Garbage Collector]

* Per Process
* After 2000 Reductions (~function calls)
* "copying semi space generational GC"
	** From space and To space
	** Collector scans root-set recursively (follows pointers to from space)
	** generational: very fresh data above the watermark, everything else is moved to old heap
	** full sweep: GC everything when high watermark is larger than free space in old heap, or with option fullsweep after (number of young GCs)
	** since OTP19: young heap can have heap-fragments: references to stuff outside it, which get copied when they are needed by the process
* Heap grows
	** Fibonacci, from 1M word on in 20% increments
	** After fullsweep 75% occupied
	** no space left
* Heap shrinks
	** after young collection live objects 25% and heap is "big"
	** fullsweep if total amount of live objects is less than 25% of heap
* Literals
* Binary = Terms larger than 64 Bytes
	** Reference counter on process heap
	** tracked in off heap virtual binary heap to trigger GC
* Message
	** Queue can be set as: `off_heap`, `on_heap`, `mixed` per process or globally:
		*** `on_heap` or `mixed`: Allocation by sender at receiver, respects main lock (e.g. during execution), increases young heap -> GC has more to do
		*** if `on_heap` fails, or set to `off_heap`: A heap fragment is created, and message is copied onto that: More expensive, than writing on heap
		*** `mixed`: Message in heap fragments are not part of root-set and skipped by GC, not sure if in OTP 19

=== Memory Management ===

Source: https://www.youtube.com/watch?v=YuPaX11vZyI[Lukas Larsson - Memory Allocators in the VM, Memory Management: Battle Stories]

* malloc can be used for everything, but slow
* Carriers contains many blocks: Block piece of memory requested by the VM
* Large blocks: Single block carriers (512kB can be configured)
* Types of data: `eheap`, `binary`, `driver`, `ets` and `temporary`, `short lived`, `long lived`, `fix size`
* Allocation strategies:
	** `Block`: best fit, address order
	** `Carrier`: address order first, carrier best fit
* Carrier alloc:
	** mseg alloc: caches freed carriers
	** sys alloc: used for main carrier alloc
* See http://erlang.org/doc/man/erts_alloc.html[`erts_alloc`]

=== Message Passing ===

* IPC solely via MP
* Messages could go over network to other node

=== Scheduler ===

Source: https://www.youtube.com/watch?v=tBAM_N9qPno[Lukas Larsson - Understanding the Erlang Scheduler]

* Standard scheduler is round-robin, priority, work-stealing
* Processes are spawned on same scheduler
* Processes run until:
	** Out of reductions: Function calls, GC, Bif calls (often depend on size of data)
	** Receive with no messages
	** BIF trap
	** busy port
* Processes are preemptive
* Three priorities: Max, high, normal+low
* Ports
	** sync with `port_command`
	** async with `port ! command`, but no notification on success
	** on same scheduler
	** not preemptive
	** erlang distribution uses basicly ports
	** ports are locked by process
	** implementation via `kqueue`, `epoll`, `selec`:
		*** 1 scheduler at a time
		*** OTP plans to have one pollset per scheduler
* Timers
	** OS time only queried on request by `now/0` and others, expensive
	** One global timer wheel
		*** protected by lock
		*** one scheduler at a time checks
		*** checking for timers: done on context switches, so no guarantees: _"wait at least x milliseconds"_
* Algorithm
	. Check if timer should be triggered
	. Check balance
	. Migrate processes/ports if exist
	. execute aux work (e.g. profiling)
	. check io
	. exec 1 port for 2000 reds
	. exec 1 process for 2000 reds
* system tries to balance ports and processes, depending on backlog
* Load balancing
	** try to stay CPU local: memory, energy saving (others sleep)
	** but utilize as much as possible, avoids sleep/wakeup
	** Task stealing:
		. Lock self
		. try to steel highest priority tasks from the highest scheduler number (compacting)
	** *Therefore priority inversion is possible, as priority is per scheduler, not system-wide*
	** Migration based on
		. max processes runq length per prio
		. total process reds
		. max process runq length total
		. max port runq length
		. total port reds
		. out of work count
		. history of last 7 balances of total reds
	** Migration:
		*** can be shut off, only stealing, "even load", with `+scl`
		*** `+sub` in OTP17: balance based on scheduler utilization, in non-full load
	** Async thread:
		*** e.g. for I/O
* NIFs
	** during NIF execution no process can be freed after exiting
	** *DON'T DO THAT*
	** Use dirty schedulers
* `+spp`: Enable port parallelism
* `+sbt`: bind scheduler to processor, only if "alone" on the system
* `+Mut false`: remove delayed alloc, *good for small RAM, embedded*, running SMP
* `+sct` on NUMA systems
* Interesting files:
	** `erl_process.c schedule`: Scheduler
	** `erl.process.c check_balance`: Rebalancing logic
	** `erl_process.h` defines influencing scheduling

=== Profiling ===

* In Erlang
	** Lock Count
	** tracing		
* In OS
	** kachegrind
	** oprofile...

== Possible Fields of Action ==

* Make options configurable
* Goal: Have soft RT and hard RT in the system at the same time

=== OS ===

* Use Hard RT OS: E.g. RTEMS

=== Processes ===

* Receiving and reacting to messages has deadlines
* Processes don't have control over their inbox => Possibilities:
	. Assume maximum message rate (maybe selective regarding the message type) and silently drop messages arriving in shorter intervals as MMR on the VM-side/One "message filtering layer" above
	. Tell the sender to STFU -> send kill signal exit(Pid, kill)
	. Combination of strategies
	. kill Alice & Bob?
* Deadlines can be missed 
	* Who has the deciding stopwatch?
		. Some kind of supervisor
		. Erlang VM
		. The process itself does not really make sense, it could have somehow locked up
	* Reaction strategies:
		. Ignore *BUT:* Severe hazard is imminent
		. Log only?
		. Possibly means our assumptions regarding the system performance/behavior are wrong
		. Means that the internal state is unforseen (e.g. a queue silently grows and grows)
		. KILL by supervisor/stopwatch, but whom?
			. Receiver?
			. Sender?
			. Both?
* http://erlang.org/doc/man/erlang.html#process_flag-2[`erlang:process_flag/2`]
	** `min_heap_size`
	** `min_bin_vheap_size` binary virtual heap size
	** `max_heap_size`: Size (`total_heap_size`) check only during GC, `kill` flag and `error_logger` can be set. "The heap size of a process is quite hard to predict, especially the amount of memory that is used during the garbage collection. When contemplating using this option, it is recommended to first run it in production with kill set to false and inspect the error_logger reports to see what the normal peak sizes of the processes in the system is and then tune the value accordingly."
	** `message_queue_data`: `off_heap` or `on_heap`. "When changing this flag messages will be moved. This work has been initiated but not completed when this function call returns."
	** `priority`: `low`, `normal`, `high`, `max`. "There is no automatic mechanism for avoiding priority inversion, such as priority inheritance or priority ceilings. When using priorities, take this into account and handle such scenarios by yourself."

=== Message Passing ===

* Distribution -> RT Networking (advanced topic)
* Mailbox -> Process -> maybe send()
* Messages between processes: RT to RT has RT constr, RT to nonRT noconstr, nonRT to RT noconstr
* External world must be assumed as RT (e.g. a bus message arrives). If a RT process receives from the socket, the socket is RT to

=== Scheduler ===

. Meta-Scheduler as proposed by Nicosia
	* Run a scheduler written in Erlang with Max Priority
	* call `process_flag(Pid, priority, Value)` to the scheduled processes
	* *Is no longer possible, as only `process_flag(Pid, save_calls, Value)` is allowed. Possibly having to do with SMP support.* Can not be found out, as pre OTP13 are not in Git.
. Write new scheduler
	* Compare different scheduling algorithms, possibly EDF
	

=== Garbage Collector ===

* Run GC after each RT task. Full sweep necessary?


=== Tasks ===

* gen_server timeout
* reaktionen / message generators in RTEMS
* GPIO pins in RTEMS als Erlang treiber
* embedded linux
* rtems time in ns
* RTEMs Docu
* Formulate Realtime Requirements in Erlang (Syntax)
* Think about a benchmark application, having soft RT tasks, and maybe a 1 or a few simple processes with strict deadlines, maybe software PWM?
	. bring it to its limits and let RT tasks miss deadlines
	. create supervisor or other mechanisms to detect deadline misses in software
* Set `min_heap_size`
* erlc -S shows BEAM assembly, guess how much memory function allocates (automate it for devs) `test_heap` gives estimate of required heap
